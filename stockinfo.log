2023-12-01 16:30:19,065:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:30:19,066:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:30:19,066:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]> returned error 61. Disconnecting.
2023-12-01 16:30:19,066:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:19,113:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:30:19,113:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]> returned error 61. Disconnecting.
2023-12-01 16:30:19,113:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:19,163:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
2023-12-01 16:30:19,163:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 61. Disconnecting.
2023-12-01 16:30:19,163:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:19,163:<module>:ERROR:NoBrokersAvailable
2023-12-01 16:30:19,163:StockPricePrediction:ERROR:name 'Consumer' is not defined
2023-12-01 16:30:19,172:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 16:30:19,172:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 16:30:19,172:_log:INFO: * Restarting with stat
2023-12-01 16:30:23,733:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:30:23,733:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:30:23,733:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]> returned error 61. Disconnecting.
2023-12-01 16:30:23,733:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:23,780:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:30:23,781:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]> returned error 61. Disconnecting.
2023-12-01 16:30:23,781:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:23,830:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
2023-12-01 16:30:23,831:connect:ERROR:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 61. Disconnecting.
2023-12-01 16:30:23,831:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. KafkaConnectionError: 61 ECONNREFUSED
2023-12-01 16:30:23,831:<module>:ERROR:NoBrokersAvailable
2023-12-01 16:30:23,831:StockPricePrediction:ERROR:name 'Consumer' is not defined
2023-12-01 16:30:23,837:_log:WARNING: * Debugger is active!
2023-12-01 16:30:23,851:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 16:42:15,826:dataGrabber:INFO:The AlphaVantage API key must be provided either through the key parameter or through the environment variable ALPHAVANTAGE_API_KEY. Get a free key from the alphavantage website: https://www.alphavantage.co/support/#api-key
2023-12-01 16:42:56,292:dataGrabber:INFO:The AlphaVantage API key must be provided either through the key parameter or through the environment variable ALPHAVANTAGE_API_KEY. Get a free key from the alphavantage website: https://www.alphavantage.co/support/#api-key
2023-12-01 16:43:06,762:dataGrabber:INFO:The AlphaVantage API key must be provided either through the key parameter or through the environment variable ALPHAVANTAGE_API_KEY. Get a free key from the alphavantage website: https://www.alphavantage.co/support/#api-key
2023-12-01 16:43:31,956:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:43:31,957:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:43:31,957:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:43:32,085:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:43:32,085:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:43:32,086:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:43:32,086:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:43:32,223:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:43:32,228:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:43:32,332:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:43:32,332:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:49:22,682:close:INFO:Closing down clientserver connection
2023-12-01 16:49:27,856:dataGrabber:INFO:The AlphaVantage API key must be provided either through the key parameter or through the environment variable ALPHAVANTAGE_API_KEY. Get a free key from the alphavantage website: https://www.alphavantage.co/support/#api-key
2023-12-01 16:51:19,531:dataGrabber:INFO:The AlphaVantage API key must be provided either through the key parameter or through the environment variable ALPHAVANTAGE_API_KEY. Get a free key from the alphavantage website: https://www.alphavantage.co/support/#api-key
2023-12-01 16:53:43,344:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:53:43,344:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:53:43,345:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:53:43,453:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:53:43,453:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:53:43,458:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:53:43,458:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:53:43,458:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:54:27,105:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:54:27,106:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:54:27,106:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:54:27,215:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:54:27,215:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:54:27,215:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:54:27,215:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:54:27,217:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:54:27,220:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:54:27,325:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:54:27,325:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:54:39,577:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 16:54:39,589:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 16:54:39,589:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 16:54:39,590:_log:INFO: * Restarting with stat
2023-12-01 16:54:44,197:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:54:44,197:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:54:44,198:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:54:44,301:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:54:44,301:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:54:44,301:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:54:44,301:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:54:44,303:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:54:44,306:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:54:44,412:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:54:44,413:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:54:57,546:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 16:54:57,556:_log:WARNING: * Debugger is active!
2023-12-01 16:54:57,576:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 16:56:22,040:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:56:22,040:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:56:22,041:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:56:22,150:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:56:22,150:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:56:22,153:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:56:22,153:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:56:22,155:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:56:22,158:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:56:22,264:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:56:22,264:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:56:33,644:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 16:56:33,646:close:INFO:Closing down clientserver connection
2023-12-01 16:58:13,289:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 16:58:13,292:close:INFO:Closing down clientserver connection
2023-12-01 16:58:13,397:_log:INFO: * Restarting with stat
2023-12-01 16:58:18,184:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:58:18,184:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:58:18,185:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:58:18,290:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:58:18,290:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:58:18,290:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:58:18,290:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:58:18,292:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:58:18,294:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:58:18,398:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:58:18,398:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:58:30,838:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 16:58:30,848:_log:WARNING: * Debugger is active!
2023-12-01 16:58:30,864:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 16:58:55,088:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 16:58:55,090:close:INFO:Closing down clientserver connection
2023-12-01 16:58:55,212:_log:INFO: * Restarting with stat
2023-12-01 16:58:59,920:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 16:58:59,920:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 16:58:59,921:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 16:59:00,024:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 16:59:00,024:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 16:59:00,025:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 16:59:00,025:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 16:59:00,026:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 16:59:00,029:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 16:59:00,134:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 16:59:00,134:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 16:59:12,882:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 16:59:12,893:_log:WARNING: * Debugger is active!
2023-12-01 16:59:12,911:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:00:00,248:close:INFO:Closing down clientserver connection
2023-12-01 17:00:00,377:close:INFO:Closing down clientserver connection
2023-12-01 17:00:06,718:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:00:06,719:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:00:06,719:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:00:06,824:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:00:06,825:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:00:06,825:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:00:06,825:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:00:06,827:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:00:06,829:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:00:06,935:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:00:06,936:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:00:18,973:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:00:18,983:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 17:00:18,983:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:00:18,984:_log:INFO: * Restarting with stat
2023-12-01 17:00:23,308:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:00:23,308:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:00:23,309:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:00:23,416:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:00:23,417:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:00:23,417:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:00:23,417:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:00:23,419:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:00:23,421:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:00:23,524:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:00:23,525:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:00:36,994:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:00:37,002:_log:WARNING: * Debugger is active!
2023-12-01 17:00:37,018:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:02:04,256:close:INFO:Closing down clientserver connection
2023-12-01 17:02:04,434:close:INFO:Closing down clientserver connection
2023-12-01 17:03:27,425:close:INFO:Closing the Kafka producer with 0 secs timeout.
2023-12-01 17:03:27,425:close:INFO:Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-12-01 17:03:58,319:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:03:58,319:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:03:58,320:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:03:58,427:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:03:58,427:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:03:58,428:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:03:58,428:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:03:58,430:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:03:58,433:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:03:58,538:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:03:58,538:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:04:36,048:close:INFO:Closing down clientserver connection
2023-12-01 17:04:55,329:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:04:55,330:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:04:55,330:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:04:55,433:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:04:55,433:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:04:55,434:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:04:55,434:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:04:55,435:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:04:55,437:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:04:55,543:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:04:55,543:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:05:08,574:close:INFO:Closing down clientserver connection
2023-12-01 17:06:39,873:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:06:39,873:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:06:39,874:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:06:39,984:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:06:39,984:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:06:39,984:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:06:39,985:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:06:39,986:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:06:39,989:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:06:40,091:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:06:40,092:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:06:58,628:close:INFO:Closing down clientserver connection
2023-12-01 17:09:45,762:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:09:45,763:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:09:45,763:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:09:45,893:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:09:45,893:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:09:45,899:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:09:45,899:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:09:45,899:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:10:10,145:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:10:10,145:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:10:10,146:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:10:10,254:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:10:10,254:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:10:10,254:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:10:10,254:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:10:10,258:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:10:10,261:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:10:10,366:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:10:10,367:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:10:23,944:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:10:23,955:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 17:10:23,955:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:10:23,956:_log:INFO: * Restarting with stat
2023-12-01 17:10:28,496:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:10:28,496:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:10:28,497:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:10:28,605:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:10:28,605:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:10:28,605:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:10:28,605:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:10:28,608:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:10:28,611:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:10:28,713:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:10:28,714:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:10:41,947:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:10:41,957:_log:WARNING: * Debugger is active!
2023-12-01 17:10:41,975:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:11:16,211:close:INFO:Closing down clientserver connection
2023-12-01 17:11:16,391:close:INFO:Closing down clientserver connection
2023-12-01 17:11:24,545:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:11:24,545:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:11:24,546:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:11:24,654:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:11:24,654:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:11:24,655:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:11:24,655:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:11:24,657:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:11:24,660:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:11:24,766:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:11:24,767:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:11:28,665:send_command:INFO:Error while receiving.
Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=4>
2023-12-01 17:11:28,668:close:INFO:Closing down clientserver connection
2023-12-01 17:11:28,668:send_command:ERROR:Exception while sending command.
Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=4>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-12-01 17:11:28,673:send_command:INFO:Error while receiving.
Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o13.sc
2023-12-01 17:11:28,675:close:INFO:Closing down clientserver connection
2023-12-01 17:11:28,675:send_command:ERROR:Exception while sending command.
Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/context.py", line 381, in signal_handler
    self.cancelAllJobs()
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/context.py", line 2446, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o13.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-12-01 17:11:28,676:close:INFO:Closing down clientserver connection
2023-12-01 17:11:28,677:StockPricePrediction:ERROR:An error occurred while calling o145.showString
2023-12-01 17:11:28,691:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 17:11:28,691:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:11:28,692:_log:INFO: * Restarting with stat
2023-12-01 17:11:29,043:close:INFO:Closing down clientserver connection
2023-12-01 17:11:37,968:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://172.31.254.167:8080
2023-12-01 17:11:37,968:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:11:37,971:_log:INFO: * Restarting with stat
2023-12-01 17:11:38,083:_log:WARNING: * Debugger is active!
2023-12-01 17:11:38,096:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:12:19,406:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:12:19,444:_log:INFO: * Restarting with stat
2023-12-01 17:12:19,571:_log:WARNING: * Debugger is active!
2023-12-01 17:12:19,582:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:12:20,596:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:12:20,632:_log:INFO: * Restarting with stat
2023-12-01 17:12:20,759:_log:WARNING: * Debugger is active!
2023-12-01 17:12:20,770:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:12:26,806:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:12:26,806:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:12:26,809:_log:INFO: * Restarting with stat
2023-12-01 17:12:26,921:_log:WARNING: * Debugger is active!
2023-12-01 17:12:26,932:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:12:44,548:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:12:44] "GET / HTTP/1.1" 200 -
2023-12-01 17:12:44,959:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:12:44] "[33mGET /data HTTP/1.1[0m" 404 -
2023-12-01 17:12:44,969:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:12:44] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2023-12-01 17:13:18,252:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:13:18,288:_log:INFO: * Restarting with stat
2023-12-01 17:13:22,869:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:13:22,870:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:13:22,870:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:13:22,979:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:13:22,979:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:13:22,979:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:13:22,979:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:13:22,981:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:13:22,984:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:13:23,086:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:13:23,087:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:13:36,181:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:13:36,191:_log:WARNING: * Debugger is active!
2023-12-01 17:13:36,209:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:14:01,417:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:14:01,419:close:INFO:Closing down clientserver connection
2023-12-01 17:14:01,552:_log:INFO: * Restarting with stat
2023-12-01 17:14:06,379:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:14:06,379:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:14:06,380:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:14:06,488:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:14:06,488:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:14:06,489:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:14:06,489:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:14:06,491:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:14:06,494:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:14:06,597:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:14:06,597:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:14:18,229:StockPricePrediction:ERROR:An error occurred while calling o145.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (vl965-172-31-254-167.wireless.umass.edu executor driver): org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: 
Bad data in pyspark.daemon's standard output. Invalid port number:
  1231975525 (0x496e7465)
Python command to execute the daemon was:
  python3 -m pyspark.daemon
Check that you don't have any unexpected modules or libraries in
your PYTHONPATH:
  /Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip:/Users/mnswdhw/miniconda/envs/playground/lib/python3.11/site-packages/pyspark/jars/spark-core_2.12-3.5.0.jar
Also, check if you have a sitecustomize.py module in your python path,
or in your python installation, that is printing to standard output
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:267)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:139)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more

2023-12-01 17:14:18,239:_log:WARNING: * Debugger is active!
2023-12-01 17:14:18,254:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:16:31,402:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 17:16:31,404:close:INFO:Closing down clientserver connection
2023-12-01 17:16:31,532:_log:INFO: * Restarting with stat
2023-12-01 17:16:34,048:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:16:34,048:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:16:34,049:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:16:34,155:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:16:34,155:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:16:34,156:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:16:34,156:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:16:34,158:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:16:34,161:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:16:34,267:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:16:34,267:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:16:35,661:_log:WARNING: * Debugger is active!
2023-12-01 17:16:35,676:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:16:53,836:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:16:53,839:close:INFO:Closing down clientserver connection
2023-12-01 17:16:53,953:_log:INFO: * Restarting with stat
2023-12-01 17:16:56,458:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:16:56,458:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:16:56,459:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:16:56,567:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:16:56,567:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:16:56,568:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:16:56,568:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:16:56,570:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:16:56,573:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:16:56,677:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:16:56,677:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:16:59,750:_log:WARNING: * Debugger is active!
2023-12-01 17:16:59,765:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:18:04,335:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:18:04,337:close:INFO:Closing down clientserver connection
2023-12-01 17:18:04,471:_log:INFO: * Restarting with stat
2023-12-01 17:18:12,516:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:18:12,516:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:18:12,516:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:18:12,621:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:18:12,622:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:18:12,622:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:18:12,622:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:18:12,625:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:18:12,627:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:18:12,733:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:18:12,733:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:18:14,827:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:18:14,827:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:18:14,827:_log:INFO: * Restarting with stat
2023-12-01 17:18:17,055:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:18:17,055:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:18:17,056:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:18:17,163:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:18:17,165:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:18:17,166:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:18:17,166:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:18:17,168:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:18:17,171:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:18:17,273:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:18:17,274:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:18:20,842:_log:WARNING: * Debugger is active!
2023-12-01 17:18:20,858:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:18:23,680:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:18:23] "GET / HTTP/1.1" 200 -
2023-12-01 17:18:23,773:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:23,776:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:23,777:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:29,781:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:29,783:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:29,785:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:18:44,070:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:18:44,072:close:INFO:Closing down clientserver connection
2023-12-01 17:18:44,188:_log:INFO: * Restarting with stat
2023-12-01 17:18:45,421:close:INFO:Closing down clientserver connection
2023-12-01 17:18:52,768:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:18:52,768:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:18:52,769:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:18:52,878:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:18:52,878:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:18:52,879:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:18:52,879:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:18:52,881:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:18:52,884:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:18:52,990:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:18:52,991:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:18:56,880:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:18:56,880:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:18:56,881:_log:INFO: * Restarting with stat
2023-12-01 17:18:59,253:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:18:59,253:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:18:59,254:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:18:59,362:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:18:59,362:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:18:59,363:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:18:59,363:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:18:59,365:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:18:59,368:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:18:59,470:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:18:59,470:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:19:02,910:_log:WARNING: * Debugger is active!
2023-12-01 17:19:02,926:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:19:06,508:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:19:06,511:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:19:06,513:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:19:19,960:close:INFO:Closing down clientserver connection
2023-12-01 17:19:20,139:close:INFO:Closing down clientserver connection
2023-12-01 17:19:23,673:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:19:23,674:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:19:23,674:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:19:23,782:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:19:23,783:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:19:23,783:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:19:23,783:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:19:23,785:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:19:23,788:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:19:23,894:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:19:23,894:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:19:26,979:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:19:26,979:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:19:26,979:_log:INFO: * Restarting with stat
2023-12-01 17:19:29,327:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:19:29,327:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:19:29,328:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:19:29,435:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:19:29,435:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:19:29,436:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:19:29,436:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:19:29,437:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:19:29,440:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:19:29,546:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:19:29,546:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:19:32,915:_log:WARNING: * Debugger is active!
2023-12-01 17:19:32,932:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:19:32,938:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:19:32,940:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:19:32,941:data:INFO:module 'Consumer' has no attribute 'LoadModel'
2023-12-01 17:20:00,186:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 17:20:00,189:close:INFO:Closing down clientserver connection
2023-12-01 17:20:00,305:_log:INFO: * Restarting with stat
2023-12-01 17:20:00,374:close:INFO:Closing down clientserver connection
2023-12-01 17:20:06,128:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:20:06,128:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:20:06,129:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:20:06,237:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:20:06,237:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:20:06,238:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:20:06,238:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:20:06,240:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:20:06,243:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:20:06,348:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:20:06,349:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:20:08,950:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:20:08,950:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:20:08,950:_log:INFO: * Restarting with stat
2023-12-01 17:20:11,162:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:20:11,163:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:20:11,163:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:20:11,268:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:20:11,268:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:20:11,269:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:20:11,269:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:20:11,271:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:20:11,275:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:20:11,378:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:20:11,378:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:20:14,979:_log:WARNING: * Debugger is active!
2023-12-01 17:20:14,997:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:20:18,907:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:20:18] "GET /data HTTP/1.1" 200 -
2023-12-01 17:20:18,908:close:INFO:Closing down clientserver connection
2023-12-01 17:20:53,352:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 17:20:53,353:close:INFO:Closing down clientserver connection
2023-12-01 17:20:53,471:_log:INFO: * Restarting with stat
2023-12-01 17:20:56,049:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:20:56,049:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:20:56,050:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:20:56,157:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:20:56,157:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:20:56,158:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:20:56,158:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:20:56,160:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:20:56,162:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:20:56,266:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:20:56,266:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:21:00,029:_log:WARNING: * Debugger is active!
2023-12-01 17:21:00,045:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:21:01,062:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 17:21:01,062:close:INFO:Closing down clientserver connection
2023-12-01 17:21:01,184:_log:INFO: * Restarting with stat
2023-12-01 17:21:03,668:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:21:03,668:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:21:03,669:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:21:03,776:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:21:03,776:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:21:03,777:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:21:03,777:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:21:03,778:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:21:03,781:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:21:03,882:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:21:03,882:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:21:04,076:close:INFO:Closing down clientserver connection
2023-12-01 17:21:10,963:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:21:10,963:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:21:10,963:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:21:11,072:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:21:11,072:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:21:11,072:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:21:11,072:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:21:11,074:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:21:11,077:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:21:11,182:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:21:11,183:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:21:15,025:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:21:15,025:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:21:15,026:_log:INFO: * Restarting with stat
2023-12-01 17:21:17,239:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:21:17,239:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:21:17,239:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:21:17,347:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:21:17,347:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:21:17,347:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:21:17,348:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:21:17,350:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:21:17,353:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:21:17,456:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:21:17,457:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:21:21,089:_log:WARNING: * Debugger is active!
2023-12-01 17:21:21,106:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:21:24,959:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:21:24] "GET /data HTTP/1.1" 200 -
2023-12-01 17:21:24,961:close:INFO:Closing down clientserver connection
2023-12-01 17:23:34,931:close:INFO:Closing the Kafka producer with 0 secs timeout.
2023-12-01 17:23:34,932:close:INFO:Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-12-01 17:23:49,345:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/producer.py', reloading
2023-12-01 17:23:49,345:close:INFO:Closing down clientserver connection
2023-12-01 17:23:49,456:_log:INFO: * Restarting with stat
2023-12-01 17:23:52,021:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:23:52,021:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:23:52,022:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:23:52,130:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:23:52,130:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:23:52,130:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:23:52,130:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:23:52,132:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:23:52,135:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:23:52,239:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:23:52,239:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:23:53,512:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:23:53,512:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:23:53,512:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:23:53,616:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:23:53,616:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:23:53,621:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:23:53,622:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:23:53,622:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:23:54,796:_log:WARNING: * Debugger is active!
2023-12-01 17:23:54,811:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:25:02,768:close:INFO:Closing down clientserver connection
2023-12-01 17:25:02,944:close:INFO:Closing down clientserver connection
2023-12-01 17:25:10,380:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:25:10,380:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:25:10,381:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:25:10,489:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:25:10,490:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:25:10,490:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:25:10,490:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:25:10,492:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:25:10,495:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:25:10,598:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:25:10,599:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:25:12,909:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 17:25:12,909:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 17:25:12,909:_log:INFO: * Restarting with stat
2023-12-01 17:25:15,134:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:25:15,134:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:25:15,134:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:25:15,238:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:25:15,238:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:25:15,238:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:25:15,239:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:25:15,240:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:25:15,243:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:25:15,347:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:25:15,347:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:25:18,905:_log:WARNING: * Debugger is active!
2023-12-01 17:25:18,923:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 17:25:44,670:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:25:44] "GET /data HTTP/1.1" 200 -
2023-12-01 17:25:44,672:close:INFO:Closing down clientserver connection
2023-12-01 17:26:01,056:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:26:01] "GET /data HTTP/1.1" 200 -
2023-12-01 17:26:01,058:close:INFO:Closing down clientserver connection
2023-12-01 17:26:19,340:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:26:19] "GET /data HTTP/1.1" 200 -
2023-12-01 17:26:19,342:close:INFO:Closing down clientserver connection
2023-12-01 17:26:25,407:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:26:25] "GET /data HTTP/1.1" 200 -
2023-12-01 17:26:25,408:close:INFO:Closing down clientserver connection
2023-12-01 17:26:37,621:_log:INFO:127.0.0.1 - - [01/Dec/2023 17:26:37] "GET /data HTTP/1.1" 200 -
2023-12-01 17:26:37,622:close:INFO:Closing down clientserver connection
2023-12-01 17:27:44,488:close:INFO:Closing down clientserver connection
2023-12-01 17:27:44,617:close:INFO:Closing down clientserver connection
2023-12-01 17:27:54,322:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:27:54,322:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:27:54,323:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:27:54,431:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:27:54,431:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:27:54,432:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:27:54,432:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:27:54,433:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:27:54,436:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:27:54,542:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:27:54,543:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:27:58,150:close:INFO:Closing down clientserver connection
2023-12-01 17:28:26,239:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:28:26,240:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:28:26,240:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:28:26,347:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:28:26,347:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:28:26,348:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:28:26,348:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:28:26,349:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:28:26,352:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:28:26,455:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:28:26,455:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:28:28,172:close:INFO:Closing down clientserver connection
2023-12-01 17:30:37,831:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 17:30:37,832:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 17:30:37,832:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 17:30:37,939:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 17:30:37,939:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 17:30:37,940:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 17:30:37,940:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 17:30:37,942:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 17:30:37,944:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 17:30:38,052:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 17:30:38,052:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 17:31:48,068:close:INFO:Closing down clientserver connection
2023-12-01 17:53:33,714:close:INFO:Closing the Kafka producer with 0 secs timeout.
2023-12-01 17:53:33,716:close:INFO:Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-12-01 18:17:47,532:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:17:47,536:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:17:47,537:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:17:47,667:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:17:47,667:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:17:47,672:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:17:47,673:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:17:47,673:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:18:19,717:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:18:19,717:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:18:19,718:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:18:19,825:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:18:19,825:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:18:19,826:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:18:19,826:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:18:19,830:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 18:18:19,832:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:18:19,934:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:18:19,935:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:18:46,661:close:INFO:Closing down clientserver connection
2023-12-01 18:18:53,683:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:18:53,683:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:18:53,683:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:18:53,791:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:18:53,792:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:18:53,792:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:18:53,792:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:18:53,795:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 18:18:53,797:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:18:53,903:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:18:53,903:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:18:54,650:close:INFO:Closing down clientserver connection
2023-12-01 18:18:59,585:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:18:59,585:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:18:59,585:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:18:59,689:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:18:59,689:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:18:59,689:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:18:59,690:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:18:59,703:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 18:18:59,704:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 18:18:59,704:_log:INFO: * Restarting with stat
2023-12-01 18:19:01,944:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:19:01,944:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:19:01,945:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:19:02,053:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:19:02,053:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:19:02,054:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:19:02,054:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:19:02,064:_log:WARNING: * Debugger is active!
2023-12-01 18:19:02,087:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 18:19:10,524:_log:INFO:127.0.0.1 - - [01/Dec/2023 18:19:10] "GET / HTTP/1.1" 200 -
2023-12-01 18:19:10,654:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 18:19:10,664:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:19:10,767:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:19:10,767:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:19:14,949:StockPricePrediction:ERROR:generator already executing
2023-12-01 18:19:16,954:_log:INFO:127.0.0.1 - - [01/Dec/2023 18:19:16] "GET /data HTTP/1.1" 200 -
2023-12-01 18:21:21,289:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 18:21:21,289:close:INFO:Closing down clientserver connection
2023-12-01 18:21:21,290:close:INFO:Closing down clientserver connection
2023-12-01 18:21:21,415:_log:INFO: * Restarting with stat
2023-12-01 18:21:24,009:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:21:24,009:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:21:24,010:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:21:24,112:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:21:24,112:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:21:24,113:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:21:24,113:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:21:24,122:_log:WARNING: * Debugger is active!
2023-12-01 18:21:24,136:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 18:23:19,215:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 18:23:19,216:close:INFO:Closing down clientserver connection
2023-12-01 18:23:19,308:_log:INFO: * Restarting with stat
2023-12-01 18:23:21,789:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:23:21,789:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:23:21,790:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:23:21,898:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:23:21,898:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:23:21,898:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:23:21,898:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:23:21,909:_log:WARNING: * Debugger is active!
2023-12-01 18:23:21,928:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 18:23:24,486:close:INFO:Closing down clientserver connection
2023-12-01 18:23:24,616:close:INFO:Closing down clientserver connection
2023-12-01 18:23:28,344:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:23:28,345:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:23:28,345:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:23:28,453:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:23:28,453:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:23:28,453:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:23:28,454:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:23:28,463:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 18:23:28,463:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 18:23:28,464:_log:INFO: * Restarting with stat
2023-12-01 18:23:30,670:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:23:30,670:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:23:30,671:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:23:30,775:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:23:30,775:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:23:30,775:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:23:30,776:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:23:30,784:_log:WARNING: * Debugger is active!
2023-12-01 18:23:30,802:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 18:23:37,907:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 18:23:37,912:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:23:38,019:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:23:38,020:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:23:40,392:data:INFO:Object of type DataFrame is not JSON serializable
2023-12-01 18:23:40,392:close:INFO:Closing down clientserver connection
2023-12-01 18:23:42,273:data:INFO:Object of type DataFrame is not JSON serializable
2023-12-01 18:23:42,273:close:INFO:Closing down clientserver connection
2023-12-01 18:23:45,270:data:INFO:Object of type DataFrame is not JSON serializable
2023-12-01 18:23:45,270:close:INFO:Closing down clientserver connection
2023-12-01 18:23:54,023:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 18:23:54,024:close:INFO:Closing down clientserver connection
2023-12-01 18:23:54,151:_log:INFO: * Restarting with stat
2023-12-01 18:23:56,685:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:23:56,686:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:23:56,686:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:23:56,794:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:23:56,794:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:23:56,795:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:23:56,795:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:23:56,807:_log:WARNING: * Debugger is active!
2023-12-01 18:23:56,828:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 18:23:56,836:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 18:23:56,838:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 18:23:56,944:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 18:23:56,944:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 18:24:00,393:_log:INFO:127.0.0.1 - - [01/Dec/2023 18:24:00] "GET /data HTTP/1.1" 200 -
2023-12-01 18:24:00,394:close:INFO:Closing down clientserver connection
2023-12-01 18:24:12,125:_log:INFO:127.0.0.1 - - [01/Dec/2023 18:24:12] "GET /data HTTP/1.1" 200 -
2023-12-01 18:24:12,126:close:INFO:Closing down clientserver connection
2023-12-01 18:24:30,161:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 18:24:30,162:close:INFO:Closing down clientserver connection
2023-12-01 18:24:30,288:_log:INFO: * Restarting with stat
2023-12-01 18:24:32,728:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 18:24:32,728:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 18:24:32,729:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 18:24:32,837:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 18:24:32,837:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 18:24:32,837:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 18:24:32,837:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 18:24:32,846:_log:WARNING: * Debugger is active!
2023-12-01 18:24:32,864:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 19:43:19,016:_maybe_close_oldest_connection:INFO:Closing idle connection 0, last active 3651044 ms ago
2023-12-01 19:43:19,085:close:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connected> [IPv4 ('172.31.254.167', 9092)]>: Closing connection. 
2023-12-01 19:43:19,428:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,430:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,485:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,485:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,538:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,538:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,591:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,591:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,717:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,718:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,772:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,772:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,825:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,825:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,905:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,906:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:19,994:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:19,995:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,063:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,063:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,116:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,116:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,169:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,169:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,224:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,224:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,278:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,278:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,348:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,348:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,402:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,402:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,456:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,457:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,512:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,512:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,566:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,566:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,619:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,619:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,673:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,673:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,725:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,725:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,778:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,778:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,829:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,830:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,890:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,890:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,933:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,934:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:20,987:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:20,987:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,039:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,039:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,091:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,091:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,142:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,142:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,193:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,193:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,244:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,244:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,294:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,295:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,347:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,347:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,403:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,404:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,452:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,452:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,504:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,505:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,556:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,556:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,609:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,609:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,661:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,661:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,713:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,713:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,765:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,765:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,817:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,818:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,870:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,870:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,922:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,922:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:21,973:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:21,974:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,027:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,028:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,077:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,078:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,130:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,130:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,179:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,179:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,231:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,232:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,284:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,284:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,336:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,336:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,386:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,387:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,440:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,440:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,492:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,492:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,546:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,547:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,595:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,595:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,646:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,647:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,697:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,697:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,749:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,749:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,800:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,801:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,853:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,853:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,905:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,905:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:22,957:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:22,958:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,010:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,010:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,061:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,062:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,114:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,114:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,165:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,165:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,217:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,217:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,270:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,270:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,321:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,321:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,374:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,374:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,425:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,425:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,477:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,477:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,528:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,529:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,581:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,582:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,633:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,634:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,689:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,690:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,744:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,745:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,794:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,794:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,844:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,844:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,901:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,901:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:23,954:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:23,954:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,004:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,004:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,055:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,055:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,108:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,108:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,159:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,159:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,212:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,213:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,264:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,264:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,315:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,316:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,367:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,367:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,419:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,419:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,470:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,470:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,523:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,523:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,576:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,576:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,630:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,630:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,682:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,682:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,735:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,736:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,786:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,786:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,838:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,838:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,888:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,888:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,941:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,942:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:24,993:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:24,994:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,048:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,048:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,096:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,097:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,148:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,148:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,199:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,199:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,251:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,252:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,304:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,304:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,355:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,356:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,417:dns_lookup:WARNING:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092, exception was [Errno 8] nodename nor servname provided, or not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2023-12-01 19:43:25,417:_dns_lookup:ERROR:DNS lookup failed for vl965-172-31-254-167.wireless.umass.edu:9092 (0)
2023-12-01 19:43:25,476:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 19:43:25,477:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 19:55:25,091:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/Consumer.py', reloading
2023-12-01 19:55:25,095:close:INFO:Closing down clientserver connection
2023-12-01 19:55:25,222:_log:INFO: * Restarting with stat
2023-12-01 19:55:28,855:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 19:55:28,855:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 19:55:28,856:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 19:55:28,964:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 19:55:28,964:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 19:55:28,965:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 19:55:28,965:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 19:55:28,974:_log:WARNING: * Debugger is active!
2023-12-01 19:55:28,994:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 20:12:21,410:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 20:12:21,413:close:INFO:Closing down clientserver connection
2023-12-01 20:12:21,533:_log:INFO: * Restarting with stat
2023-12-01 20:12:24,084:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:12:24,085:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:12:24,085:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:12:24,193:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:12:24,193:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:12:24,194:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:12:24,194:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:12:25,200:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:12:25,200:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:12:25,200:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:12:25,308:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:12:25,308:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:12:25,309:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:12:25,309:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:12:25,311:_log:WARNING: * Debugger is active!
2023-12-01 20:12:25,322:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 20:12:25,327:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 20:12:25,333:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 20:12:25,433:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 20:12:25,433:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 20:12:39,450:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:12:39] "GET /data HTTP/1.1" 200 -
2023-12-01 20:12:58,257:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:12:58] "GET /data HTTP/1.1" 200 -
2023-12-01 20:16:49,975:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:16:49] "GET /data HTTP/1.1" 200 -
2023-12-01 20:18:59,652:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:18:59] "[33mGET /null HTTP/1.1[0m" 404 -
2023-12-01 20:19:06,964:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:19:06] "[33mGET /null HTTP/1.1[0m" 404 -
2023-12-01 20:25:45,748:_log:INFO: * Detected change in '/Users/mnswdhw/Documents/Courses/CS532/Stock_Data_Prediction/Stock_Data_Prediction_Of_Live_Data/app.py', reloading
2023-12-01 20:25:59,721:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:25:59] "GET /data HTTP/1.1" 200 -
2023-12-01 20:26:59,190:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:26:59] "GET /data HTTP/1.1" 200 -
2023-12-01 20:28:56,847:close:INFO:Closing down clientserver connection
2023-12-01 20:28:57,009:close:INFO:Closing down clientserver connection
2023-12-01 20:31:08,618:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:31:08,618:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:31:08,619:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:31:08,727:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:31:08,727:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:31:08,728:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:31:08,728:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:31:08,929:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:31:08,929:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:31:08,930:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:31:09,037:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:31:09,037:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:31:09,037:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:31:09,037:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:31:09,040:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 20:31:09,040:_log:INFO:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:8080
2023-12-01 20:31:09,040:_log:INFO:[33mPress CTRL+C to quit[0m
2023-12-01 20:31:09,040:_log:INFO: * Restarting with stat
2023-12-01 20:31:09,042:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 20:31:09,148:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 20:31:09,148:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 20:31:11,253:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:31:11,254:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:31:11,254:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:31:11,358:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:31:11,358:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:31:11,358:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:31:11,359:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:31:11,509:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2023-12-01 20:31:11,509:check_version:INFO:Probing node bootstrap-0 broker version
2023-12-01 20:31:11,509:connect:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2023-12-01 20:31:11,617:check_version:INFO:Broker version identified as 2.5.0
2023-12-01 20:31:11,617:check_version:INFO:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2023-12-01 20:31:11,617:__init__:WARNING:group_id is None: disabling auto-commit.
2023-12-01 20:31:11,617:change_subscription:INFO:Updating subscribed topics to: ('stock_data',)
2023-12-01 20:31:11,619:_log:WARNING: * Debugger is active!
2023-12-01 20:31:11,630:assign_from_subscribed:INFO:Updated partition assignment: [TopicPartition(topic='stock_data', partition=0)]
2023-12-01 20:31:11,634:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: connecting to vl965-172-31-254-167.wireless.umass.edu:9092 [('172.31.254.167', 9092) IPv4]
2023-12-01 20:31:11,646:_log:INFO: * Debugger PIN: 514-370-077
2023-12-01 20:31:11,739:connect:INFO:<BrokerConnection node_id=0 host=vl965-172-31-254-167.wireless.umass.edu:9092 <connecting> [IPv4 ('172.31.254.167', 9092)]>: Connection complete.
2023-12-01 20:31:11,740:close:INFO:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2023-12-01 20:31:22,120:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:22] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:25,138:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:25] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:28,159:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:28] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:31,179:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:31] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:34,197:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:34] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:37,213:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:37] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:40,230:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:40] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:43,248:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:43] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:46,266:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:46] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:49,283:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:49] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:52,300:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:52] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:55,319:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:55] "GET /data HTTP/1.1" 200 -
2023-12-01 20:31:58,339:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:31:58] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:01,357:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:01] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:04,375:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:04] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:07,392:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:07] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:10,410:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:10] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:13,427:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:13] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:16,446:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:16] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:19,465:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:19] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:22,483:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:22] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:25,502:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:25] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:28,521:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:28] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:31,543:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:31] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:34,561:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:34] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:37,580:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:37] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:40,598:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:40] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:43,615:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:43] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:46,629:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:46] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:49,645:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:49] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:52,663:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:52] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:55,680:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:55] "GET /data HTTP/1.1" 200 -
2023-12-01 20:32:58,698:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:32:58] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:01,722:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:01] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:04,738:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:04] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:07,843:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:07] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:10,960:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:10] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:14,080:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:14] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:17,163:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:17] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:20,280:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:20] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:23,392:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:23] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:26,511:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:26] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:29,626:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:29] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:32,734:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:32] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:35,839:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:35] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:38,946:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:38] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:42,065:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:42] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:45,178:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:45] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:48,284:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:48] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:51,404:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:51] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:54,527:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:54] "GET /data HTTP/1.1" 200 -
2023-12-01 20:33:57,647:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:33:57] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:00,688:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:00] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:03,810:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:03] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:06,932:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:06] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:10,051:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:10] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:13,075:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:13] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:16,093:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:16] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:19,110:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:19] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:22,127:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:22] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:25,144:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:25] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:28,162:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:28] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:31,180:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:31] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:34,197:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:34] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:37,215:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:37] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:40,233:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:40] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:43,250:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:43] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:46,268:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:46] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:49,289:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:49] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:52,361:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:52] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:55,478:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:55] "GET /data HTTP/1.1" 200 -
2023-12-01 20:34:58,576:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:34:58] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:01,695:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:01] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:04,807:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:04] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:07,922:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:07] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:11,037:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:11] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:14,149:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:14] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:17,261:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:17] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:20,380:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:20] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:23,400:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:23] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:26,419:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:26] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:29,443:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:29] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:32,464:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:32] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:35,503:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:35] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:38,608:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:38] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:41,726:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:41] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:44,842:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:44] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:47,957:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:47] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:51,075:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:51] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:54,193:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:54] "GET /data HTTP/1.1" 200 -
2023-12-01 20:35:57,304:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:35:57] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:00,423:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:00] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:03,540:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:03] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:06,662:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:06] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:09,772:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:09] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:12,893:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:12] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:16,004:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:16] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:19,113:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:19] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:22,201:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:22] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:25,308:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:25] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:28,411:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:28] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:31,530:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:31] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:34,645:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:34] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:35,667:close:INFO:Closing the Kafka producer with 0 secs timeout.
2023-12-01 20:36:35,668:close:INFO:Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2023-12-01 20:36:37,755:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:37] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:40,864:_log:INFO:127.0.0.1 - - [01/Dec/2023 20:36:40] "GET /data HTTP/1.1" 200 -
2023-12-01 20:36:46,266:close:INFO:Closing down clientserver connection
